{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Case Study - B3</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading df_cleaned and resetting Dtypes\n",
    "df = pd.read_csv(\"df_cleaned.csv\")\n",
    "df['id_cliente']=df['id_cliente'].astype(str)\n",
    "df[['renda', 'profissao']] = df[['renda', 'profissao']].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Nome          |Período|Unidade|Descrição                        |\n",
    "|:-------------|-----  |------|--------------------------------- |\n",
    "|id_cliente    |N/A    |N/A   |Id único que identifica cliente   |\n",
    "|renda         |N/A    |R\\$   |Faixa de renda declarada          |\n",
    "|profissao     |N/A    |N/A   |Grupo de profissões agrupadas     |\n",
    "|qt_compras    |M0     |ativos|Quantidade de ativos adquiridos   |\n",
    "|val_compra    |M0     |R\\$    |Valor total das ações compradas   |\n",
    "|tm_compra     |M0     |R\\$   |Valor por ação - compra (“ticket”)|\n",
    "|qt_vendas     |M0     |ativos|Quantidade de ativos vendidos    |\n",
    "|val_venda     |M0     |R\\$    |Valor total das ações vendidas    |\n",
    "|tm_venda      |M0     |R\\$    |Valor por ação - venda (“ticket”) |\n",
    "|dif_cv        |M0     |ativos |Diferença entre compra e venda de ativos     |\n",
    "|acoes         |M0     |#     |# ações na carteira               |\n",
    "|acoes_dif     |M0     |#     |# ações diferentes na carteira    |\n",
    "|ativo_m1      |M1     |Flag  |1=Cliente está ativo em M1        |\n",
    "|ligou_cr_m1   |M1     |Flag  |1=Contato na central em M1        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although exploratory analysis provides some interesting indicators, we can raise the bar in our analysis with machine learning models to see which features help predict the variable that matters in our case: **ativo_m1**.\n",
    "\n",
    "In other words, how can we determine whether a customer is about to leave next month, to optimize the work of customer relationship managers (and offer reduced prices, if that's the case) without unnecessarily inconveniencing others?\n",
    "\n",
    "Next, I will use two forecasting techniques: **Logistic Regression** and **Random Forest**.\n",
    "\n",
    "Logistic Regression is useful for being able to work with continuous and discrete data. However, unlike Linear Regression, it is not easy to compare performance of models with many vs. few independent variables (there is no concept of residuals, so it is not possible to use the least squares (cost function) to calculate the R²) - For this, we test whether the effect of the independent variable in predicting the dependent is significantly different from 0 ( using Wald's Test, or Z test - I didn't use Chi-square). If not (=0), it means the variable is not helping. In other words, we use the concept of 'maximum likelihood' (we calculate the observation probability of all points on the X axis to be y=0 and y=1 (Sigmoid function converts the input into a range 0-1), and we multiply all the probabilities/likelihood together; then we move the \"S\" line several times and calculate the same thing until we find the curve with 'maximum likelihood'). To do this, we calculate the probability of leaving the brokerage house by the total number of people who left the brokerage house divided by the total number of customers. Then we multiply this probability by the total number of customers who have a specific independent variable. This will be the expected number of clients that have the independent variable AND have left the broker. And the rest is the expected number of clients that have the independent variable E will not leave the broker. Then we do the same (probability of leaving the broker (already calculated) x total number of clients who DO NOT have this same independent variable (and subtraction)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we need to turn categorical variables into dummy variables - binary \"switches\" that turn the parameters in the equation on or off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qt_compras</th>\n",
       "      <th>val_compra</th>\n",
       "      <th>tm_compra</th>\n",
       "      <th>qt_vendas</th>\n",
       "      <th>val_venda</th>\n",
       "      <th>tm_venda</th>\n",
       "      <th>dif_cv</th>\n",
       "      <th>acoes</th>\n",
       "      <th>acoes_dif</th>\n",
       "      <th>ativo_m1</th>\n",
       "      <th>renda_De 0 a 5k</th>\n",
       "      <th>renda_De 10 a 15k</th>\n",
       "      <th>renda_De 15 a 20k</th>\n",
       "      <th>renda_De 5 a 10k</th>\n",
       "      <th>profissao_A</th>\n",
       "      <th>profissao_B</th>\n",
       "      <th>profissao_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.01</td>\n",
       "      <td>2941.26</td>\n",
       "      <td>29.41</td>\n",
       "      <td>-100.01</td>\n",
       "      <td>9900</td>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>599.90</td>\n",
       "      <td>9388.48</td>\n",
       "      <td>15.65</td>\n",
       "      <td>-599.90</td>\n",
       "      <td>7800</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1600</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.08</td>\n",
       "      <td>4488.88</td>\n",
       "      <td>11.22</td>\n",
       "      <td>-400.08</td>\n",
       "      <td>7200</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200.0</td>\n",
       "      <td>3340.07</td>\n",
       "      <td>16.7</td>\n",
       "      <td>199.98</td>\n",
       "      <td>4143.59</td>\n",
       "      <td>20.72</td>\n",
       "      <td>0.02</td>\n",
       "      <td>4400</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qt_compras  val_compra  tm_compra  qt_vendas  val_venda  tm_venda  dif_cv  \\\n",
       "0         0.0        0.00        0.0     100.01    2941.26     29.41 -100.01   \n",
       "1         0.0        0.00        0.0     599.90    9388.48     15.65 -599.90   \n",
       "2         0.0        0.00        0.0       0.00       0.00      0.00    0.00   \n",
       "3         0.0        0.00        0.0     400.08    4488.88     11.22 -400.08   \n",
       "4       200.0     3340.07       16.7     199.98    4143.59     20.72    0.02   \n",
       "\n",
       "   acoes  acoes_dif  ativo_m1  renda_De 0 a 5k  renda_De 10 a 15k  \\\n",
       "0   9900         40      True                1                  0   \n",
       "1   7800         20      True                0                  0   \n",
       "2   1600          5     False                1                  0   \n",
       "3   7200         30      True                0                  0   \n",
       "4   4400         10      True                0                  0   \n",
       "\n",
       "   renda_De 15 a 20k  renda_De 5 a 10k  profissao_A  profissao_B  profissao_C  \n",
       "0                  0                 0            0            1            0  \n",
       "1                  0                 1            1            0            0  \n",
       "2                  0                 0            1            0            0  \n",
       "3                  0                 1            0            0            1  \n",
       "4                  0                 1            0            1            0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = ['renda','profissao'] # the categorical features\n",
    "\n",
    "df_dummy = pd.get_dummies(df, columns = cat_features)\n",
    "df_dummy.drop(['id_cliente','ligou_cr_m1'], axis=1, inplace=True) # leaving only independent variables\n",
    "\n",
    "df_dummy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to separate test data from training data so as not to have a complex model with a very good fit with the data, as it may not be generalist enough to work with new data (overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dummy.loc[:, df_dummy.columns != 'ativo_m1']\n",
    "y = df_dummy.loc[:, df_dummy.columns == 'ativo_m1']\n",
    "\n",
    "# test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "columns = X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in the exploratory analysis, classes are unbalanced (89/11).\n",
    "\n",
    "One way to resolve unbalanced datasets is \"oversample\" the smaller class. That\n",
    "One approach to addressing imbalanced datasets is to oversmple the minority class. The simplest approach involves duplicating examples in the minority class, although these examples do not add any new information to the model. Instead, new examples can be synthesized from existing examples. This is a type of data augmentation for the minority class and is referred to as the Synthetic Minority Oversampling Technique, or SMOTE.\n",
    "\n",
    "At a high level, SMOTE works by creating synthetic secondary class samples (unsigned) rather than creating copies.\n",
    "Randomly choosing one of the nearest k-nearest-neighbors and using it to create new observations similar but randomly adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os = SMOTE(random_state = 0)\n",
    "\n",
    "os_df_X, os_df_y = os.fit_sample(X_train, y_train)\n",
    "os_df_X = pd.DataFrame(data = os_df_X, columns = columns)\n",
    "os_df_y = pd.DataFrame(data = os_df_y, columns = ['ativo_m1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to round up because logistic regression gives error with infinite floats: *ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_df_X = os_df_X.round()\n",
    "os_df_y = os_df_y.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the oversampled data is  12436\n",
      "Number of clients who left the broker in M1 is  6218\n",
      "Number of customers who continued with the broker in M1 is 6218\n",
      "Proportion of customers who left in M1 in the oversampled data is of  0.5\n",
      "Proportion of customers who continued in M1 in the oversampled data is  0.5\n"
     ]
    }
   ],
   "source": [
    "# checking the distribution of datasets after SMOTE\n",
    "\n",
    "print(\"Size of the oversampled data is \", len(os_df_X))\n",
    "print(\"Number of clients who left the broker in M1 is \", len(os_df_y[os_df_y['ativo_m1'] == False]))\n",
    "print(\"Number of customers who continued with the broker in M1 is\", len(os_df_y[os_df_y['ativo_m1'] == True]))\n",
    "print(\"Proportion of customers who left in M1 in the oversampled data is of \", len(os_df_y[os_df_y['ativo_m1'] == 0]) / len(os_df_X))\n",
    "print(\"Proportion of customers who continued in M1 in the oversampled data is \", len(os_df_y[os_df_y['ativo_m1'] == 1]) / len(os_df_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have balanced data.\n",
    "\n",
    "I decided to apply SMOTE only to the training data (X_train, y_train) because, that way, no information from the test data is being used to create synthetic observations - that is, no information will come out of the test data for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression - initial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.301415\n",
      "         Iterations 10\n",
      "                          Results: Logit\n",
      "==================================================================\n",
      "Model:                Logit            Pseudo R-squared: 0.565    \n",
      "Dependent Variable:   ativo_m1         AIC:              7528.7849\n",
      "Date:                 2021-07-14 15:56 BIC:              7647.6385\n",
      "No. Observations:     12436            Log-Likelihood:   -3748.4  \n",
      "Df Model:             15               LL-Null:          -8620.0  \n",
      "Df Residuals:         12420            LLR p-value:      0.0000   \n",
      "Converged:            1.0000           Scale:            1.0000   \n",
      "No. Iterations:       10.0000                                     \n",
      "------------------------------------------------------------------\n",
      "                   Coef.  Std.Err.    z     P>|z|   [0.025  0.975]\n",
      "------------------------------------------------------------------\n",
      "qt_compras         0.5759   0.7406   0.7775 0.4368 -0.8758  2.0275\n",
      "val_compra         0.0002   0.0001   3.1933 0.0014  0.0001  0.0003\n",
      "tm_compra         -0.0923   0.0080 -11.5249 0.0000 -0.1080 -0.0766\n",
      "qt_vendas         -0.5510   0.7406  -0.7439 0.4569 -2.0026  0.9007\n",
      "val_venda          0.0003   0.0001   4.6919 0.0000  0.0002  0.0004\n",
      "tm_venda          -0.0881   0.0083 -10.5801 0.0000 -0.1044 -0.0717\n",
      "dif_cv            -0.5622   0.7406  -0.7591 0.4478 -2.0139  0.8894\n",
      "acoes             -0.0003   0.0000 -24.7362 0.0000 -0.0003 -0.0002\n",
      "acoes_dif          0.0677   0.0034  20.0543 0.0000  0.0611  0.0744\n",
      "renda_De 0 a 5k   -1.9616   0.0701 -27.9745 0.0000 -2.0991 -1.8242\n",
      "renda_De 10 a 15k  0.0455   0.1314   0.3464 0.7290 -0.2121  0.3032\n",
      "renda_De 15 a 20k  0.9154   0.2558   3.5789 0.0003  0.4141  1.4167\n",
      "renda_De 5 a 10k  -0.6368   0.0983  -6.4791 0.0000 -0.8295 -0.4442\n",
      "profissao_A        1.9046   0.0964  19.7497 0.0000  1.7156  2.0936\n",
      "profissao_B       -0.5419   0.0758  -7.1463 0.0000 -0.6905 -0.3933\n",
      "profissao_C       -0.2256   0.0770  -2.9302 0.0034 -0.3765 -0.0747\n",
      "==================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = os_df_X\n",
    "y = os_df_y['ativo_m1']\n",
    "\n",
    "import statsmodels.api as sm\n",
    "logit_model = sm.Logit(y,X)\n",
    "result = logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25% of p-values are statistically insignificant - let's try to improve this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this study, I will use **Recursive Feature Elimination**, **Decision Trees** and the **VIF** method to eliminate multicollinearity and arrive at the most important features in predicting the independent variable **ativo_m1**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recursive Feature Elimination\n",
    "\n",
    "Recursive Feature Elimination (RFE) is based on the idea of repeatedly creating a model and choosing which one has the best feature performance, leaving the feature aside and repeating the process with the rest of the features. This process is applied until all features in the dataset are exhausted. The goal is to select features by considering recursively smaller and smaller amounts of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False False False\n",
      " False  True False False]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 9, 15,  7, 11, 13, 12, 10, 14,  8,  6,  4,  3,  5,  0,  2,  1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='liblinear', max_iter=100)\n",
    "\n",
    "rfe = RFE(logreg, n_features_to_select=1)\n",
    "rfe = rfe.fit(os_df_X, os_df_y.values.ravel())\n",
    "\n",
    "print(rfe.support_)\n",
    "order = rfe.ranking_ - 1\n",
    "order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordering, to improve the visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9. renda_De 0 a 5k',\n",
       " '15. profissao_C',\n",
       " '7. acoes',\n",
       " '11. renda_De 15 a 20k',\n",
       " '13. profissao_A',\n",
       " '12. renda_De 5 a 10k',\n",
       " '10. renda_De 10 a 15k',\n",
       " '14. profissao_B',\n",
       " '8. acoes_dif',\n",
       " '6. dif_cv',\n",
       " '4. val_venda',\n",
       " '3. qt_vendas',\n",
       " '5. tm_venda',\n",
       " '0. qt_compras',\n",
       " '2. tm_compra',\n",
       " '1. val_compra']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_rank = []\n",
    "for i in order:\n",
    "    feature_rank.append(f\"{i}. {os_df_X.columns[i]}\")\n",
    "feature_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to note that information on purchases and sales (quantity, values and average ticket) is more important in predicting y - but must have high collinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Trees\n",
    "\n",
    "Decision trees (DTs) are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from data resources. A tree can be seen as a constant approximation in parts.\n",
    "\n",
    "A tree is built by dividing the source set, constituting the root node of the tree, into subsets - which constitute the successor children. Division is based on a set of division rules based on classification characteristics. This process is repeated on each derived subset in a recursive manner called recursive partitioning. Recursion is completed when the subset within a node has all the same target variable values, or when the split no longer adds value to the predictions.\n",
    "\n",
    "Official document: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=10, random_state=15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=15, criterion = 'entropy', max_depth = 10) # entropy = criterion for calculating information gain / random_state = random number generator\n",
    "dt.fit(os_df_X,os_df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature importance for qt_compras is : 0.3286770895369566\n",
      "The feature importance for val_compra is : 0.010070407356842545\n",
      "The feature importance for tm_compra is : 0.0032020566669006723\n",
      "The feature importance for qt_vendas is : 0.38968738902194006\n",
      "The feature importance for val_venda is : 0.002800062240591695\n",
      "The feature importance for tm_venda is : 0.010548456945992076\n",
      "The feature importance for dif_cv is : 0.01646783079208373\n",
      "The feature importance for acoes is : 0.028911234926423047\n",
      "The feature importance for acoes_dif is : 0.10514926838412052\n",
      "The feature importance for renda_De 0 a 5k is : 0.0003785305386830202\n",
      "The feature importance for renda_De 10 a 15k is : 0.0008295703973727613\n",
      "The feature importance for renda_De 15 a 20k is : 0.0\n",
      "The feature importance for renda_De 5 a 10k is : 0.002192014644367496\n",
      "The feature importance for profissao_A is : 0.07122563745918158\n",
      "The feature importance for profissao_B is : 0.019527249469957167\n",
      "The feature importance for profissao_C is : 0.010333201618587064\n"
     ]
    }
   ],
   "source": [
    "# Running Feature Importance\n",
    "\n",
    "fi_col = []\n",
    "fi = []\n",
    "\n",
    "for i,column in enumerate(os_df_X):\n",
    "    print('The feature importance for {} is : {}'.format(column, dt.feature_importances_[i]))\n",
    "    \n",
    "    fi_col.append(column)\n",
    "    fi.append(dt.feature_importances_[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordering, to improve the visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Feature Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>qt_vendas</td>\n",
       "      <td>0.389687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>qt_compras</td>\n",
       "      <td>0.328677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>acoes_dif</td>\n",
       "      <td>0.105149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>profissao_A</td>\n",
       "      <td>0.071226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>acoes</td>\n",
       "      <td>0.028911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>profissao_B</td>\n",
       "      <td>0.019527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>dif_cv</td>\n",
       "      <td>0.016468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>tm_venda</td>\n",
       "      <td>0.010548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>profissao_C</td>\n",
       "      <td>0.010333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>val_compra</td>\n",
       "      <td>0.010070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>tm_compra</td>\n",
       "      <td>0.003202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>val_venda</td>\n",
       "      <td>0.002800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>renda_De 5 a 10k</td>\n",
       "      <td>0.002192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>renda_De 10 a 15k</td>\n",
       "      <td>0.000830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>renda_De 0 a 5k</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11</td>\n",
       "      <td>renda_De 15 a 20k</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index            Feature  Feature Importance\n",
       "0       3          qt_vendas            0.389687\n",
       "1       0         qt_compras            0.328677\n",
       "2       8          acoes_dif            0.105149\n",
       "3      13        profissao_A            0.071226\n",
       "4       7              acoes            0.028911\n",
       "5      14        profissao_B            0.019527\n",
       "6       6             dif_cv            0.016468\n",
       "7       5           tm_venda            0.010548\n",
       "8      15        profissao_C            0.010333\n",
       "9       1         val_compra            0.010070\n",
       "10      2          tm_compra            0.003202\n",
       "11      4          val_venda            0.002800\n",
       "12     12   renda_De 5 a 10k            0.002192\n",
       "13     10  renda_De 10 a 15k            0.000830\n",
       "14      9    renda_De 0 a 5k            0.000379\n",
       "15     11  renda_De 15 a 20k            0.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a Dataframe\n",
    "fi_dt = zip(fi_col, fi)\n",
    "fi_dt = pd.DataFrame(fi_dt, columns = ['Feature','Feature Importance'])\n",
    "\n",
    "# Sorting the data\n",
    "fi_dt = fi_dt.sort_values('Feature Importance', ascending = False).reset_index()\n",
    "\n",
    "fi_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quantities of purchases and sales remain at the top, as in the case of the RFE, but information regarding actions and professions also appears.\n",
    "\n",
    "Multicollinearity is also an issue for Decision Trees. Decision trees make no assumptions about the relationships between resources. It just builds divisions on single features that improve rank, based on a measure of impurity like Gini or entropy. If the resources *qt_vendas* and *tm_venda* are strongly correlated, no / little information can be obtained from the division into *tm_venda* after the division into *qt_vendas*. In the case of multicollinearity, this will likely mean that they will fit the most effective variable they find, leaving out other plausible variables. There is a material probability that the algorithm fits not on the 'right' variable, but on a strong variable correlated with the right variable, since which predictor is chosen to partition the samples is essentially a random selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multicollinearity & VIF technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multicollinearity occurs when there are two or more independent variables in a multiple regression model, which have a high correlation with each other. When some features are highly correlated, we may have difficulty distinguishing between their individual effects on the dependent variable. Multicollinearity can be detected using several techniques, one of which is the Variance Inflation Factor (VIF).\n",
    "​\n",
    "In the VIF method, we pick each feature and regress it against all other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              feature           VIF\n",
      "0          qt_compras  4.380152e+07\n",
      "1          val_compra  1.619987e+01\n",
      "2           tm_compra  3.591717e+00\n",
      "3           qt_vendas  4.501439e+07\n",
      "4           val_venda  1.490042e+01\n",
      "5            tm_venda  3.648959e+00\n",
      "6              dif_cv  4.618898e+07\n",
      "7               acoes  6.139464e+00\n",
      "8           acoes_dif  4.391648e+00\n",
      "9     renda_De 0 a 5k  2.655966e+00\n",
      "10  renda_De 10 a 15k  2.410159e+00\n",
      "11  renda_De 15 a 20k  2.078291e+00\n",
      "12   renda_De 5 a 10k  2.324807e+00\n",
      "13        profissao_A  2.157061e+00\n",
      "14        profissao_B  2.113511e+00\n",
      "15        profissao_C  2.154427e+00\n"
     ]
    }
   ],
   "source": [
    "# VIF dataframe\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = os_df_X.columns\n",
    "\n",
    "# calculando VIF para cada feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(os_df_X.values, i)\n",
    "                          for i in range(len(os_df_X.columns))]\n",
    "  \n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a rule, a VIF greater than 2 already indicates multicollinearity.\n",
    "\n",
    "To choose the features, I used a combination of:\n",
    "- Variables that were detected as important in both RFE and Decision Trees (qt_vendas, qt_compras, acoes_dif, renda e profissão))\n",
    "- Categorical variables that showed a trend in the Exploratory Analysis (renda e profissão)) and can give important signals in the approach of Customer Relationship agents\n",
    "- Elimination of features with high multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             feature       VIF\n",
      "0    renda_De 0 a 5k  2.185256\n",
      "1  renda_De 10 a 15k  2.166856\n",
      "2  renda_De 15 a 20k  1.833100\n",
      "3   renda_De 5 a 10k  2.130369\n",
      "4        profissao_A  2.082712\n",
      "5        profissao_B  2.029286\n",
      "6        profissao_C  2.069068\n",
      "7          qt_vendas  1.817082\n",
      "8         qt_compras  1.840882\n",
      "9          acoes_dif  2.318576\n"
     ]
    }
   ],
   "source": [
    "cols_reduced = ['renda_De 0 a 5k', \n",
    "        'renda_De 10 a 15k', \n",
    "        'renda_De 15 a 20k',\n",
    "        'renda_De 5 a 10k',\n",
    "        'profissao_A',\n",
    "        'profissao_B',\n",
    "        'profissao_C', \n",
    "        'qt_vendas', \n",
    "        'qt_compras',\n",
    "        'acoes_dif']\n",
    "\n",
    "X_reduced = os_df_X[cols_reduced]\n",
    "y_reduced = os_df_y['ativo_m1']\n",
    "  \n",
    "# VIF dataframe\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X_reduced.columns\n",
    "\n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_reduced.values, i)\n",
    "                          for i in range(len(X_reduced.columns))]\n",
    "  \n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was a significant improvement, now we go to logistic regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression - final analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.348541\n",
      "         Iterations 9\n",
      "                          Results: Logit\n",
      "==================================================================\n",
      "Model:                Logit            Pseudo R-squared: 0.497    \n",
      "Dependent Variable:   ativo_m1         AIC:              8688.9183\n",
      "Date:                 2021-07-14 15:56 BIC:              8763.2018\n",
      "No. Observations:     12436            Log-Likelihood:   -4334.5  \n",
      "Df Model:             9                LL-Null:          -8620.0  \n",
      "Df Residuals:         12426            LLR p-value:      0.0000   \n",
      "Converged:            1.0000           Scale:            1.0000   \n",
      "No. Iterations:       9.0000                                      \n",
      "------------------------------------------------------------------\n",
      "                   Coef.  Std.Err.    z     P>|z|   [0.025  0.975]\n",
      "------------------------------------------------------------------\n",
      "renda_De 0 a 5k   -2.4259   0.0639 -37.9457 0.0000 -2.5512 -2.3006\n",
      "renda_De 10 a 15k -0.6060   0.1197  -5.0614 0.0000 -0.8407 -0.3713\n",
      "renda_De 15 a 20k  0.0159   0.2185   0.0730 0.9418 -0.4123  0.4442\n",
      "renda_De 5 a 10k  -1.1572   0.0877 -13.2013 0.0000 -1.3290 -0.9854\n",
      "profissao_A        1.6007   0.0904  17.7151 0.0000  1.4236  1.7778\n",
      "profissao_B       -0.6253   0.0691  -9.0480 0.0000 -0.7608 -0.4898\n",
      "profissao_C       -0.3886   0.0702  -5.5360 0.0000 -0.5262 -0.2510\n",
      "qt_vendas          0.0104   0.0003  34.5002 0.0000  0.0098  0.0110\n",
      "qt_compras         0.0100   0.0003  34.1551 0.0000  0.0095  0.0106\n",
      "acoes_dif          0.0022   0.0014   1.5906 0.1117 -0.0005  0.0048\n",
      "==================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "logit_model = sm.Logit(y_reduced,X_reduced)\n",
    "result = logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "\n",
    "- Pseudo R-squared: explaining almost 50% of the variation in *ativo_m1* (although it is not the ideal indicator, as R² in the OLS - here it is the ratio of the logarithmic probability of the null model to the full model.)\n",
    "- The Z-test (ratio of Coef/Std.Err) is a way of testing whether the effect of the independent variable in predicting the dependent variable is significantly different from 0.\n",
    "- Coefficients predict changes in log odds of the dependent variable for each unit augmented in the independent variable. Positive values ​​indicate that an increase in the explanatory variable also predicts an increase in the probability associated with the dependent variable. For example, when the customer has *profissao_A* (changes from 0 to 1), the cumulative probability of the customer being active (changes from 0 to 1) increases by exp(1,6007) - with 95% confidence interval of being between 1.4236 - 1.7778.\n",
    "- Negative coefficients indicate the opposite: for example, when the customer has *renda_De 0 a 5k* (changes from 0 to 1), the cumulative probability of the customer being active (changes from 0 to 1) reduces exp(2.4259) - with 95 % confidence interval lies between -2.5512 - -2.3006.\n",
    "\n",
    "\n",
    "That said, we can see that:\n",
    "- The lower the income, the greater the likelihood of ativo_m1 = 0 (leaving the broker in M1). Especially if it's less than 10K. Proving deductions from the exploratory analysis and indicating that the problem may be that lower-income customers are looking for more competitive prices;\n",
    "- Professions B and C are more likely to leave the brokerage house, also proving deductions from the exploratory analysis;\n",
    "- Quantity of assets bought and sold do not have significant difference in the forecast of ativo_m1. In the exploratory analysis, \"having sold more assets than bought is not necessarily a good indicator that the client exited in M1 (mean dif_cv smaller/negative)\"\n",
    "- Having a larger amount of different stocks does not explain ativo_m1 forecast significantly either. In the exploratory analysis: \"clients who remained in M1 have an average of # different shares and generally higher than clients who left, but there are outliers in active clients in M1 that pull the average up\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting Test Sets and Calculating Accuracy\n",
    "\n",
    "Accuracy is the ratio of correct predictions to total predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using scikit-learn LogisticRegression (applies regularization)\n",
    "# By default, scikit-learn‘s logistic regression applies regularization (e por isso pode ser diferente do statsmodel Logit). Regularization balances the need for predictive accuracy on the training data with a penalty on the magnitude of the model coefficients. Increasing the penalty reduces the coefficients and hence reduces the likelihood of overfitting. If the penalty is too large, though, it will reduce predictive power on both the training and test data. We can set turn off regularization by setting penalty as none.\n",
    "logreg = LogisticRegression(solver='liblinear', max_iter=100)\n",
    "logreg.fit(X_reduced, y_reduced.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression in test set: 0.93\n"
     ]
    }
   ],
   "source": [
    "X_test_reduced = X_test[cols_reduced]\n",
    "y_test_reduced = y_test['ativo_m1']\n",
    "\n",
    "y_pred = logreg.predict(X_test_reduced)\n",
    "print('Accuracy of logistic regression in test set: {:.2f}'.format(logreg.score(X_test_reduced, y_test_reduced)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model accuracy: 93%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 279,   41],\n",
       "       [ 170, 2510]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Viewing Confusion Matrix\n",
    "cm = confusion_matrix(y_test_reduced, y_pred)\n",
    "cm_norm = cm / cm.sum(axis=1).reshape(-1,1) # each line divided by the sum of the line (percent)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes=None, title='Confusion matrix'):\n",
    "    \"\"\"Plota um Confusion Matrix\"\"\"\n",
    "    if classes is not None:\n",
    "        sns.heatmap(cm, cmap=\"YlGnBu\", xticklabels=classes, yticklabels=classes, vmin=0., vmax=1., annot=True, annot_kws={'size':50})\n",
    "    else:\n",
    "        sns.heatmap(cm, vmin=0., vmax=1.)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "plot_confusion_matrix(cm_norm, classes = logreg.classes_, title='Confusion matrix')\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result tells us that there were 279 (87% of the y's that were negative and the model predicted as negative) + 2510 (94% of the y's that were positive and we predicted as positive). A total of 2789 correct predictions, against 41+170=211 incorrect predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute precision, recall, F-measure and support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quoting Scikit Learn:\n",
    "\n",
    "Precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp is the number of false positives. Precision is intuitively the classifier's ability not to label a sample as positive if it is negative.\n",
    "\n",
    "Recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. Recall is intuitively the classifier's ability to find all positive samples.\n",
    "\n",
    "The F-beta score can be interpreted as a harmonic weighted average of accuracy and recall, where an F-beta score reaches its best value of 1 and the worst score of 0.\n",
    "\n",
    "The F-beta score weights recall more than accuracy by a beta factor. beta = 1.0 means that recall and accuracy are equally important.\n",
    "\n",
    "Support is the number of occurrences of each class in y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.62      0.87      0.73       320\n",
      "        True       0.98      0.94      0.96      2680\n",
      "\n",
      "    accuracy                           0.93      3000\n",
      "   macro avg       0.80      0.90      0.84      3000\n",
      "weighted avg       0.95      0.93      0.93      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_reduced, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ROC (Receiver Operating Characteristic) curve is a graph that shows the performance of a classification model across all classification thresholds. This curve represents two parameters: True Positive Rate and False Positive Rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logit_roc_auc = roc_auc_score(y_test_reduced, logreg.predict(X_test_reduced))\n",
    "fpr, tpr, thresholds = roc_curve(y_test_reduced, logreg.predict_proba(X_test_reduced)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dotted line represents the ROC curve of a purely random classifier. Classifiers that provide curves closer to the upper left corner indicate better performance. As a baseline, a random classifier is expected to provide points along the diagonal (FPR = TPR). The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is one of the most popular \"ensemble\" methods for supervised machine learning and is capable of performing both regression and classification.\n",
    "\n",
    "RF develops a “forest” by building a multitude of decision trees. Because of its Bootstrap Aggregation and Feature Randomness algorithms, Random Forests can handle large data sets and numerical and categorical variables with high dimensionality, without overfitting (unlike a regular decision tree) or needing to be standardized (Hastie, et al., 2009). Furthermore, by using a random subset of variables, it reduces the correlations in the tree (Breiman, 2001), producing a more accurate prediction (Ho, 1995) and avoiding multicollinearity of features.\n",
    "\n",
    "Due to its mixed method of Bootstrap Aggregation with Feature Randomness, it is possible to measure the importance of each feature, as well as estimate the strength of the ensemble, correlation and generalization error (PE) in each division of the tree, allowing the model to be adjusted and validated during training (Breiman, 2001; Hastie, Tibshirani, & Friedman, 2009).\n",
    "\n",
    "In summary, it is a very simple and complete \"out of the box\" algorithm.\n",
    "\n",
    "The number of 100 decision trees was defined for the set as n_estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-4e3dee9c2517>:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  forest_clas.fit(os_df_X, os_df_y) # training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03233190689212125"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clas = RandomForestClassifier(n_estimators=100)\n",
    "forest_clas.fit(os_df_X, os_df_y) # training\n",
    "\n",
    "predictions = forest_clas.predict(os_df_X)\n",
    "forest_mse = mean_squared_error(os_df_y, predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typical error of 0.03 with Random Forest Classifier. Even better than Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00      6218\n",
      "        True       1.00      1.00      1.00      6218\n",
      "\n",
      "    accuracy                           1.00     12436\n",
      "   macro avg       1.00      1.00      1.00     12436\n",
      "weighted avg       1.00      1.00      1.00     12436\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(os_df_y,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features ordenadas pelo score:\n",
      "[(0.1695, 'qt_vendas'), (0.1568, 'qt_compras'), (0.1229, 'val_compra'), (0.1135, 'acoes_dif'), (0.0972, 'val_venda'), (0.0812, 'dif_cv'), (0.079, 'acoes'), (0.0499, 'profissao_A'), (0.0497, 'tm_venda'), (0.0449, 'tm_compra'), (0.0092, 'renda_De 5 a 10k'), (0.0075, 'profissao_C'), (0.006, 'profissao_B'), (0.0053, 'renda_De 0 a 5k'), (0.0047, 'renda_De 10 a 15k'), (0.0027, 'renda_De 15 a 20k')]\n"
     ]
    }
   ],
   "source": [
    "features = df_dummy.loc[:, df_dummy.columns != 'ativo_m1']\n",
    "\n",
    "print(\"Features ordenadas pelo score:\")\n",
    "print(sorted(zip(map(lambda x: float(\"{0:.5f}\".format(round(x, 4))), forest_clas.feature_importances_), features),\n",
    "             reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier confirms the suggestion of the most important features of Features Extraction and Exploratory Analysis: *qt_compras*, *qt_vendas* e *acoes_dif*, in addition to *profissao_A* and *renda_De 5 to 10k*, despite their reduced importance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
